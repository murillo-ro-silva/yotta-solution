# Initialize Spark session
# Creates or retrieves a SparkSession named "Spark Playground".
from pyspark.sql import SparkSession
import pyspark.sql.functions as sf

spark = SparkSession.builder.appName('Spark Playground').getOrCreate()

# Enter the file path for the input JSON file.
file_path = "/datasets/orders.json"

# Read the JSON file using the 'multiline' option to properly parse multi-line JSON data.
df = spark.read.option("multiline","true").json(file_path)

# Data Transformation
# Explode the "products" array so each product becomes a separate row.
df_exploded = (
  df.select(
    "customer_id",
    "order_id",
    sf.explode("products").alias("product")
  )
)

# Select the required columns from the exploded rows.
df_results = (
  df_exploded.select(
    sf.col("customer_id"),
    sf.col("order_id"),
    sf.col("product.product_name").alias("product_name"),
    sf.col("product.product_price").alias("product_price"),
  )
)

# Display the final DataFrame containing all the flattened data.
display(df_results)
